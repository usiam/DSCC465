{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aad2427",
   "metadata": {},
   "source": [
    "<h1 align='center'> DSCC 465 HW 02 <h1>\n",
    "    <h3 align='right'> Uzair Tahamid Siam </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3e4673",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2a234f",
   "metadata": {},
   "source": [
    "\\begin{enumerate}\n",
    "\\item\n",
    "Let, the hypothesis be that the car is behind door 1. And we want to find the probability that the car is behind door 1 given that the door opened has a goat behind it. We will use ! to represent not. So,\n",
    "$$C = \\text{The car is behind door 1}$$ $$G = \\text{The goat is behind the door opened}$$\n",
    "\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "    P(C|G) &= \\frac{P(G|C) P(C)}{P(G)}\n",
    "\\end{align*}\n",
    "\n",
    "We can write the marginal probability of the host showing a goat as,\n",
    "\\begin{align*}\n",
    "    P(G) = P(G|C)P(C) + P(G|!C) P(!C)\n",
    "\\end{align*}\n",
    "This gives us all the possibilities of the host showing the goat regardless of whether door 1 has a car or not. \n",
    "\n",
    "\\begin{align*}\n",
    "    P(G|C) = P(G \\cap C)/P(C) = (1/3)/(1/3) = 1\n",
    "\\end{align*}\n",
    "The probability of having the goat behind the door that was opened given that the car is behind door 1 is just 1. Because the door with the car will obviously not be opened. \n",
    "\n",
    "\\begin{align*}\n",
    "    P(G|!C) = P(G \\cap !C)/P(!C) = (2/3)/(2/3) = 1\n",
    "\\end{align*}\n",
    "The probability that the host shows the goat, given that there is a goat behind door 1, is again always 1. The host always shows a door with a goat. \n",
    "\n",
    "From the problem itself we know that, $P(C) = 1/3$ ($P(!C)=1-P(C)=2/3$) and that is our prior. \n",
    "\n",
    "\\begin{align*}\n",
    "    \\therefore P(G) = (1/3) + (2/3) = 1\n",
    "\\end{align*}\n",
    "Which again makes sense because the host will always open a door that has a goat. He will never open a door with a car. \n",
    "\n",
    "So, now we can find,\n",
    "\n",
    "\\begin{align*}\n",
    "    P(C|G) &= \\frac{P(G|C) P(C)}{P(G)}\\\\\n",
    "    &= \\frac{(1) \\cdot (1/3)}{1} = 1/3\n",
    "\\end{align*}\n",
    "\n",
    "We also find that,\n",
    "\\begin{align*}\n",
    "     P(!C|G) = 1 -  P(C|G) = 2/3\n",
    "\\end{align*}\n",
    "\n",
    "This shows us that it is more probable that the car is not behind door 1. So, we can conclude that it is more advantageous to switch.\n",
    "\n",
    "\n",
    "\\item For the two teams to reach the $7^{th}$ game team A has to win 3 games and has to lose 3 games (i.e. team B wins the 3 games). This is just a binomial distribution since there are n-trials with a binary possibility. So, let $P(A) = 0.55$ be the probability that A wins and $P(B) = 0.45$ be the probability that A loses (i.e B wins). There are multiple combinations possible for A to win 3 games and lose 3 games. To be exact there are 6C3 = 20 possible combinations. E.g. WWWLLL/WWLLWL/LLLWWW/and so on. So we can compute the probability as,\n",
    "\n",
    "\\begin{align*}\n",
    "    P_{6}(3) &= {6 \\choose 3} (P(A))^3 (P(B))^3\\\\\n",
    "    &= {6 \\choose 3} (0.55)^3 (0.45)^3 \\\\\n",
    "    &\\approx 0.3032\n",
    "\\end{align*}\n",
    "\n",
    "\\item See below\n",
    "\\item See below\n",
    "\\item See below\n",
    "\\end{enumerate}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb76119a",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7c7746b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T00:35:23.531022Z",
     "start_time": "2022-02-06T00:35:21.838161Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import pandas as pd\n",
    "from numpy.typing import ArrayLike\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e159a0b2",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c426568",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T00:35:23.545439Z",
     "start_time": "2022-02-06T00:35:23.532240Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing california housing data from sklearn \n",
    "\n",
    "dataset = sklearn.datasets.fetch_california_housing(as_frame=True).frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4db8be88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T00:35:23.548304Z",
     "start_time": "2022-02-06T00:35:23.546256Z"
    }
   },
   "outputs": [],
   "source": [
    "x = dataset.iloc[:, :-1]\n",
    "y = dataset.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46840e45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T00:35:23.567099Z",
     "start_time": "2022-02-06T00:35:23.549084Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dividing into training and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=265)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46bed5bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T00:35:23.574405Z",
     "start_time": "2022-02-06T00:35:23.568786Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalizing the data i.e. feature scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "x_train = sc_x.fit_transform(x_train)\n",
    "x_test = sc_x.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65486e97",
   "metadata": {},
   "source": [
    "## Q3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427823f6",
   "metadata": {},
   "source": [
    "Gradient: \n",
    "$$\\nabla_{\\theta}J = (2/m) \\matrix{X}^{T}({X}\\theta - \\vec{y})$$\n",
    "\n",
    "$X = $ feature matrix\n",
    "\n",
    "$\\theta = $ weights\n",
    "\n",
    "$m = $ number of data objects\n",
    "\n",
    "$X\\theta = $ prediction\n",
    "\n",
    "$\\vec{y} = $ targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d503dc",
   "metadata": {},
   "source": [
    "MSE function: \n",
    "$$J(\\vec{\\theta}) = (1/2m)(X\\theta - \\vec{y})^{2}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feda4c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dfa353fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T00:35:23.582401Z",
     "start_time": "2022-02-06T00:35:23.575238Z"
    },
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "def cost(theta: ArrayLike, X: ArrayLike, y: ArrayLike) -> int:\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta: numpy.typing.ArrayLike\n",
    "        The weights that are to be optimized\n",
    "    \n",
    "    X: numpy.typing.ArrayLike\n",
    "        Numpy Array of features\n",
    "    \n",
    "    y: numpy.typing.ArrayLike\n",
    "        Numpy Array of targets\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    mse: int\n",
    "        Returns the mean-square-error between the predicted and actual target values\n",
    "    '''\n",
    "    m = len(y) # number of data\n",
    "    y_pred = np.dot(X, theta) # calculating X*theta\n",
    "    mse = 1/(2*m)*((y_pred - y)**2)  # calculating the error function \n",
    "\n",
    "    return mse\n",
    "\n",
    "def gradient(theta:ArrayLike, X:ArrayLike, y:ArrayLike)->ArrayLike:\n",
    "    '''\n",
    "    '''\n",
    "    m = len(y) # number of data\n",
    "    err = np.dot(X, theta) - y # error/residue term\n",
    "    grad = 2/m * np.dot(X.T, err) # finding the gradient using the vector form\n",
    "    \n",
    "    return grad\n",
    " \n",
    "def gradient_descent(X: ArrayLike, y:ArrayLike, number_of_steps: int = 1000, learning_rate: int = 0.01, plot:bool = False) -> ArrayLike:\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta: numpy.typing.ArrayLike\n",
    "        The weights that are to be optimized\n",
    "    \n",
    "    X: numpy.typing.ArrayLike\n",
    "        Numpy Array of features\n",
    "    \n",
    "    y: numpy.typing.ArrayLike\n",
    "        Numpy Array of targets\n",
    "        \n",
    "    number_of_steps: int\n",
    "        Number of iterations for the gradient descent algorithm\n",
    "        \n",
    "    learning_rate: int\n",
    "        Often called alpha. Used as a multiplier for the step-size\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    theta: int\n",
    "        Returns the optimized values of the weights initially given as a parameter\n",
    "    '''\n",
    "    \n",
    "    y_reshaped = np.reshape(y, (len(y), 1)) # reshaping for calculation\n",
    "    new_X = np.c_[np.ones((len(X), 1)), X] # appending a column of 1 to X for intercept\n",
    "    theta = np.random.randn(len(X[0])+1, 1) # initializing the weights and also the intercept\n",
    "    m = len(y) # number of data\n",
    "    cost_lst = [] # saving cost for plotting\n",
    "\n",
    "    for i in range(number_of_steps): # initializing the iterations\n",
    "        gradients = gradient(theta, new_X, y_reshaped) # finding the gradient using the initial theta\n",
    "        theta = theta - learning_rate * gradients # finding the new weights\n",
    "        y_pred = np.dot(new_X, theta) # finding the new prediction value\n",
    "        if plot:\n",
    "            cost_value = cost(theta, new_X, y_reshaped) # finding the new cost if plotting\n",
    "            # calculating the total cost\n",
    "            total = 0\n",
    "            for i in range(len(y)):\n",
    "                total += cost_value[i][0] \n",
    "                #Calculate the cost function for each iteration\n",
    "\n",
    "                cost_lst.append(total)\n",
    "    if plot:\n",
    "        plt.plot(np.arange(1,number_of_steps),cost_lst[1:], color = 'red')\n",
    "        plt.title('MSE Plot')\n",
    "        plt.xlabel('Number of iterations')\n",
    "        plt.ylabel('Cost')\n",
    "        \n",
    "    intercept_ = theta[0][0]   \n",
    "    \n",
    "    return {'intercept':intercept_, 'weights':theta[1:].flatten()}\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2705354",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T00:35:23.720563Z",
     "start_time": "2022-02-06T00:35:23.583281Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intercept': 2.0660607482611555,\n",
       " 'weights': array([ 0.95173487,  0.17742949, -0.40748083,  0.40257876,  0.01243974,\n",
       "        -0.04845525, -0.35121777, -0.32949271])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you wish to plot the cost please set plot as True in the argument\n",
    "\n",
    "gradient_descent(x_train, y_train.values, number_of_steps= 1000, learning_rate= 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3079c28c",
   "metadata": {},
   "source": [
    "## Interpretation:\n",
    "\n",
    "The intercept represents the median value of the house if every feature had a value of 0.\n",
    "\n",
    "If we are to assume that the data follows rules of linearity, then from our analysis we can make the following claims:\n",
    "\n",
    "> 1) The median income has the highest positive trend with the median value of a house. This makes complete sense as if you make more money you are probably living in a high income area which also results in higher prices in housing.\n",
    "\n",
    "> 2) The lattitude and longitudes have the most negative trend with the value. I am not sure what to make of this observation given my lack of knowledge in both the housing industry as well as what living at different longi/lattitude means.\n",
    "\n",
    "> 3) The population and average occupation seem to have the lowest correlation to the house pricing. Kind of surprising to me as you would expect some sort of correlation between population in a region and how expensive it might be to get land/build housing ia highly populated region. But at least it does show slightly negative impact as expected.\n",
    "\n",
    "> 4) The higher the age of the house the more expensive the house appears to be. This is truly surprising to me as I would expect newer houses to be more expensive.\n",
    "\n",
    "> 5) The more *BEDROOMS* the higher the price but the more *TOTAL* rooms the lower the price. I suppose this kind of makes sense. If you have more bedrooms you do expect the house to be bigger but also if there's too many rooms that are not bedrooms people might not want to buy the house as a result decreasing the price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2a23e1",
   "metadata": {},
   "source": [
    "# Q4 \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8172218",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T00:35:23.784588Z",
     "start_time": "2022-02-06T00:35:23.721818Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using sklearn's Stochastic Gradient Descent Regression algorithm\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "reg = SGDRegressor(loss='squared_error',random_state=265, max_iter=1000, alpha=0.01)\n",
    "\n",
    "# training the data\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "# getting the optimized weights\n",
    "weights = reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "766970ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T00:35:23.821216Z",
     "start_time": "2022-02-06T00:35:23.785949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights:\n",
      "[ 0.8415846   0.12309233 -0.2766104   0.28230879 -0.01295436 -0.03037704\n",
      " -0.80087347 -0.76047679]\n",
      "intercept:\n",
      "[2.06235155]\n"
     ]
    }
   ],
   "source": [
    "print(f\"weights:\\n{weights}\")\n",
    "print(f\"intercept:\\n{reg.intercept_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c4018e",
   "metadata": {},
   "source": [
    "## Interpretation:\n",
    "\n",
    "*The behavior is very comparable to that seen in our analysis done in Q3. Of course this was to be expected as we are using similar techniques. The values for the weights do not completely align (i.e they are not 1:1) but the trends are all the same and so are the relative magnitudes of the weights. The slight decrepencies are likely to be a result of a suboptimized self-made gradient descent function compared to the more professionally developed sklearn module's regressor. But nonetheless given enough steps in our own gradient descent function, the two do get very close. (Feel free to run it for number_of_steps = 5000 and check for yourself)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4fad8c",
   "metadata": {},
   "source": [
    "## Q5\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2245a32c",
   "metadata": {},
   "source": [
    "$$cov(X) = E[(X-E[X])(X-E[X])^{T}]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f32534c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T00:35:23.825399Z",
     "start_time": "2022-02-06T00:35:23.822535Z"
    }
   },
   "outputs": [],
   "source": [
    "def cov_like_np(X: ArrayLike) -> ArrayLike:\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: numpy.typing.ArrayLike\n",
    "        Numpy Array for covariance calculation\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    cov: numpy.typing.ArrayLike\n",
    "        Numpy Array representing the covariance of the input matrix X\n",
    "    '''\n",
    "    X = np.array(X)\n",
    "    EX = np.mean(X, axis=1).reshape(len(X), 1) # finding mean of each col in X and reshaping for subtraction\n",
    "    diff = np.subtract(X, EX) # finding X - EX\n",
    "    prod = np.dot(diff, diff.T)\n",
    "    cov = prod/(len(X[0])-1)\n",
    "    return cov\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8ead631f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T00:37:41.053381Z",
     "start_time": "2022-02-06T00:37:41.044192Z"
    }
   },
   "outputs": [],
   "source": [
    "def cov_like_pd(X: ArrayLike, asFrame:bool = True) -> ArrayLike:\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: numpy.typing.ArrayLike\n",
    "        Numpy Array for covariance calculation\n",
    "    \n",
    "    asFrame: bool\n",
    "        User input for return type as a dataframe or numpy array\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    cov: numpy.typing.ArrayLike\n",
    "        Numpy Array representing the covariance of the input matrix X\n",
    "    '''\n",
    "    I = np.ones((len(X), len(X)))   \n",
    "    EX = np.dot(I, X)/(X.shape[0]) # finding the expectation of X by multiplying by I and divide by the number of rows\n",
    "    diff = np.subtract(X,EX) # finding X - EX\n",
    "    cov = np.dot(diff.T, diff)/(X.shape[0]-1) \n",
    "    return pd.DataFrame.from_records(cov) if asFrame else cov\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533b3cfb",
   "metadata": {},
   "source": [
    "### Pandas Like Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0b1c5402",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T00:38:07.699197Z",
     "start_time": "2022-02-06T00:38:07.673474Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.609323</td>\n",
       "      <td>-2.846140</td>\n",
       "      <td>1.536568</td>\n",
       "      <td>-0.055858</td>\n",
       "      <td>1.040098e+01</td>\n",
       "      <td>0.370289</td>\n",
       "      <td>-0.323860</td>\n",
       "      <td>-0.057765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.846140</td>\n",
       "      <td>158.396260</td>\n",
       "      <td>-4.772882</td>\n",
       "      <td>-0.463718</td>\n",
       "      <td>-4.222271e+03</td>\n",
       "      <td>1.724298</td>\n",
       "      <td>0.300346</td>\n",
       "      <td>-2.728244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.536568</td>\n",
       "      <td>-4.772882</td>\n",
       "      <td>6.121533</td>\n",
       "      <td>0.993868</td>\n",
       "      <td>-2.023337e+02</td>\n",
       "      <td>-0.124689</td>\n",
       "      <td>0.562235</td>\n",
       "      <td>-0.136518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.055858</td>\n",
       "      <td>-0.463718</td>\n",
       "      <td>0.993868</td>\n",
       "      <td>0.224592</td>\n",
       "      <td>-3.552723e+01</td>\n",
       "      <td>-0.030424</td>\n",
       "      <td>0.070575</td>\n",
       "      <td>0.012670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.400979</td>\n",
       "      <td>-4222.270582</td>\n",
       "      <td>-202.333712</td>\n",
       "      <td>-35.527225</td>\n",
       "      <td>1.282470e+06</td>\n",
       "      <td>821.712002</td>\n",
       "      <td>-263.137814</td>\n",
       "      <td>226.377839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.370289</td>\n",
       "      <td>1.724298</td>\n",
       "      <td>-0.124689</td>\n",
       "      <td>-0.030424</td>\n",
       "      <td>8.217120e+02</td>\n",
       "      <td>107.870026</td>\n",
       "      <td>0.052492</td>\n",
       "      <td>0.051519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.323860</td>\n",
       "      <td>0.300346</td>\n",
       "      <td>0.562235</td>\n",
       "      <td>0.070575</td>\n",
       "      <td>-2.631378e+02</td>\n",
       "      <td>0.052492</td>\n",
       "      <td>4.562293</td>\n",
       "      <td>-3.957054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.057765</td>\n",
       "      <td>-2.728244</td>\n",
       "      <td>-0.136518</td>\n",
       "      <td>0.012670</td>\n",
       "      <td>2.263778e+02</td>\n",
       "      <td>0.051519</td>\n",
       "      <td>-3.957054</td>\n",
       "      <td>4.014139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0            1           2          3             4           5  \\\n",
       "0   3.609323    -2.846140    1.536568  -0.055858  1.040098e+01    0.370289   \n",
       "1  -2.846140   158.396260   -4.772882  -0.463718 -4.222271e+03    1.724298   \n",
       "2   1.536568    -4.772882    6.121533   0.993868 -2.023337e+02   -0.124689   \n",
       "3  -0.055858    -0.463718    0.993868   0.224592 -3.552723e+01   -0.030424   \n",
       "4  10.400979 -4222.270582 -202.333712 -35.527225  1.282470e+06  821.712002   \n",
       "5   0.370289     1.724298   -0.124689  -0.030424  8.217120e+02  107.870026   \n",
       "6  -0.323860     0.300346    0.562235   0.070575 -2.631378e+02    0.052492   \n",
       "7  -0.057765    -2.728244   -0.136518   0.012670  2.263778e+02    0.051519   \n",
       "\n",
       "            6           7  \n",
       "0   -0.323860   -0.057765  \n",
       "1    0.300346   -2.728244  \n",
       "2    0.562235   -0.136518  \n",
       "3    0.070575    0.012670  \n",
       "4 -263.137814  226.377839  \n",
       "5    0.052492    0.051519  \n",
       "6    4.562293   -3.957054  \n",
       "7   -3.957054    4.014139  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_like_pd(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a41006f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T00:35:24.910830Z",
     "start_time": "2022-02-06T00:35:24.900101Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MedInc</th>\n",
       "      <td>3.609323</td>\n",
       "      <td>-2.846140</td>\n",
       "      <td>1.536568</td>\n",
       "      <td>-0.055858</td>\n",
       "      <td>1.040098e+01</td>\n",
       "      <td>0.370289</td>\n",
       "      <td>-0.323860</td>\n",
       "      <td>-0.057765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HouseAge</th>\n",
       "      <td>-2.846140</td>\n",
       "      <td>158.396260</td>\n",
       "      <td>-4.772882</td>\n",
       "      <td>-0.463718</td>\n",
       "      <td>-4.222271e+03</td>\n",
       "      <td>1.724298</td>\n",
       "      <td>0.300346</td>\n",
       "      <td>-2.728244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AveRooms</th>\n",
       "      <td>1.536568</td>\n",
       "      <td>-4.772882</td>\n",
       "      <td>6.121533</td>\n",
       "      <td>0.993868</td>\n",
       "      <td>-2.023337e+02</td>\n",
       "      <td>-0.124689</td>\n",
       "      <td>0.562235</td>\n",
       "      <td>-0.136518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AveBedrms</th>\n",
       "      <td>-0.055858</td>\n",
       "      <td>-0.463718</td>\n",
       "      <td>0.993868</td>\n",
       "      <td>0.224592</td>\n",
       "      <td>-3.552723e+01</td>\n",
       "      <td>-0.030424</td>\n",
       "      <td>0.070575</td>\n",
       "      <td>0.012670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Population</th>\n",
       "      <td>10.400979</td>\n",
       "      <td>-4222.270582</td>\n",
       "      <td>-202.333712</td>\n",
       "      <td>-35.527225</td>\n",
       "      <td>1.282470e+06</td>\n",
       "      <td>821.712002</td>\n",
       "      <td>-263.137814</td>\n",
       "      <td>226.377839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AveOccup</th>\n",
       "      <td>0.370289</td>\n",
       "      <td>1.724298</td>\n",
       "      <td>-0.124689</td>\n",
       "      <td>-0.030424</td>\n",
       "      <td>8.217120e+02</td>\n",
       "      <td>107.870026</td>\n",
       "      <td>0.052492</td>\n",
       "      <td>0.051519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Latitude</th>\n",
       "      <td>-0.323860</td>\n",
       "      <td>0.300346</td>\n",
       "      <td>0.562235</td>\n",
       "      <td>0.070575</td>\n",
       "      <td>-2.631378e+02</td>\n",
       "      <td>0.052492</td>\n",
       "      <td>4.562293</td>\n",
       "      <td>-3.957054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Longitude</th>\n",
       "      <td>-0.057765</td>\n",
       "      <td>-2.728244</td>\n",
       "      <td>-0.136518</td>\n",
       "      <td>0.012670</td>\n",
       "      <td>2.263778e+02</td>\n",
       "      <td>0.051519</td>\n",
       "      <td>-3.957054</td>\n",
       "      <td>4.014139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MedInc     HouseAge    AveRooms  AveBedrms    Population  \\\n",
       "MedInc       3.609323    -2.846140    1.536568  -0.055858  1.040098e+01   \n",
       "HouseAge    -2.846140   158.396260   -4.772882  -0.463718 -4.222271e+03   \n",
       "AveRooms     1.536568    -4.772882    6.121533   0.993868 -2.023337e+02   \n",
       "AveBedrms   -0.055858    -0.463718    0.993868   0.224592 -3.552723e+01   \n",
       "Population  10.400979 -4222.270582 -202.333712 -35.527225  1.282470e+06   \n",
       "AveOccup     0.370289     1.724298   -0.124689  -0.030424  8.217120e+02   \n",
       "Latitude    -0.323860     0.300346    0.562235   0.070575 -2.631378e+02   \n",
       "Longitude   -0.057765    -2.728244   -0.136518   0.012670  2.263778e+02   \n",
       "\n",
       "              AveOccup    Latitude   Longitude  \n",
       "MedInc        0.370289   -0.323860   -0.057765  \n",
       "HouseAge      1.724298    0.300346   -2.728244  \n",
       "AveRooms     -0.124689    0.562235   -0.136518  \n",
       "AveBedrms    -0.030424    0.070575    0.012670  \n",
       "Population  821.712002 -263.137814  226.377839  \n",
       "AveOccup    107.870026    0.052492    0.051519  \n",
       "Latitude      0.052492    4.562293   -3.957054  \n",
       "Longitude     0.051519   -3.957054    4.014139  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.cov(pd.DataFrame.from_records(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c77ec9",
   "metadata": {},
   "source": [
    "### Numpy Like Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d1968252",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T00:35:28.318747Z",
     "start_time": "2022-02-06T00:35:24.914861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 15828.51059651, 100411.06909593,  22911.52253488, ...,\n",
       "         43698.7069652 ,  32878.34650356,  59154.88863585],\n",
       "       [100411.06909593, 726902.76879646, 152324.56887559, ...,\n",
       "        307726.22523876, 227636.95255885, 422082.4403021 ],\n",
       "       [ 22911.52253488, 152324.56887559,  33722.95864622, ...,\n",
       "         65602.13612302,  49048.98091119,  89243.70502233],\n",
       "       ...,\n",
       "       [ 43698.7069652 , 307726.22523876,  65602.13612302, ...,\n",
       "        131028.86321045,  97274.06321906, 179228.804142  ],\n",
       "       [ 32878.34650356, 227636.95255885,  49048.98091119, ...,\n",
       "         97274.06321906,  72373.786035  , 132831.76856219],\n",
       "       [ 59154.88863585, 422082.4403021 ,  89243.70502233, ...,\n",
       "        179228.804142  , 132831.76856219, 245479.08714416]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_like_np(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7256a3b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T00:35:30.896493Z",
     "start_time": "2022-02-06T00:35:28.319860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 15828.51059651, 100411.06909593,  22911.52253488, ...,\n",
       "         43698.7069652 ,  32878.34650356,  59154.88863585],\n",
       "       [100411.06909593, 726902.76879646, 152324.56887559, ...,\n",
       "        307726.22523876, 227636.95255885, 422082.4403021 ],\n",
       "       [ 22911.52253488, 152324.56887559,  33722.95864622, ...,\n",
       "         65602.13612302,  49048.98091119,  89243.70502233],\n",
       "       ...,\n",
       "       [ 43698.7069652 , 307726.22523876,  65602.13612302, ...,\n",
       "        131028.86321045,  97274.06321906, 179228.804142  ],\n",
       "       [ 32878.34650356, 227636.95255885,  49048.98091119, ...,\n",
       "         97274.06321906,  72373.786035  , 132831.76856219],\n",
       "       [ 59154.88863585, 422082.4403021 ,  89243.70502233, ...,\n",
       "        179228.804142  , 132831.76856219, 245479.08714416]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff251f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
